{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Skin Cancer Classification and Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 2. Data Loading and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata with column names\n",
    "column_names = ['image_id'] + [f'class_{i}' for i in range(7)]\n",
    "metadata = pd.read_csv('archive/GroundTruth.csv', header=None, names=column_names)\n",
    "\n",
    "# Define class names\n",
    "class_names = [\n",
    "    'melanoma',\n",
    "    'nevus',\n",
    "    'basal_cell_carcinoma',\n",
    "    'actinic_keratosis',\n",
    "    'benign_keratosis',\n",
    "    'dermatofibroma',\n",
    "    'vascular_lesion'\n",
    "]\n",
    "\n",
    "# Convert one-hot to dx column\n",
    "metadata['dx'] = metadata.iloc[:, 1:8].idxmax(axis=1)\n",
    "metadata['dx'] = metadata['dx'].str.replace('class_', '').map(lambda x: class_names[int(x)])\n",
    "\n",
    "# Check for duplicates\n",
    "if metadata.duplicated().any():\n",
    "    print(\"Warning: Duplicates found. Removing duplicates.\")\n",
    "    metadata = metadata.drop_duplicates()\n",
    "\n",
    "# Split data\n",
    "try:\n",
    "    train_df, temp_df = train_test_split(metadata, test_size=0.3, stratify=metadata['dx'])\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['dx'])\n",
    "except ValueError as e:\n",
    "    print(f\"Splitting error: {e}\")\n",
    "    print(\"Consider merging rare classes or using a different strategy.\")\n",
    "    raise\n",
    "\n",
    "# Reset indices\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print stats\n",
    "print(f\"\\nTraining set: {len(train_df)}\")\n",
    "print(f\"Validation set: {len(val_df)}\")\n",
    "print(f\"Test set: {len(test_df)}\")\n",
    "\n",
    "# Check corrupt samples with optional mask requirement\n",
    "def check_corrupt_samples(df, image_dir, mask_dir=None, require_masks=False):\n",
    "    corrupt_indices = []\n",
    "    for idx in tqdm(range(len(df)), desc=\"Checking corrupt files\"):\n",
    "        img_name = df.loc[idx, 'image_id'] + '.jpg'\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        \n",
    "        # Check image\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                img.verify()\n",
    "        except (IOError, OSError, ValueError) as e:\n",
    "            print(f\"Corrupt or missing image {img_path}: {e}\")\n",
    "            corrupt_indices.append(idx)\n",
    "            continue\n",
    "        \n",
    "        # Check mask only if required\n",
    "        if require_masks and mask_dir:\n",
    "            mask_name = df.loc[idx, 'image_id'] + '_segmentation.png'  # Updated to match actual naming\n",
    "            mask_path = os.path.join(mask_dir, mask_name)\n",
    "            if os.path.exists(mask_path):\n",
    "                try:\n",
    "                    with Image.open(mask_path) as mask:\n",
    "                        mask.verify()\n",
    "                except (IOError, OSError, ValueError) as e:\n",
    "                    print(f\"Corrupt or missing mask {mask_path}: {e}\")\n",
    "                    corrupt_indices.append(idx)\n",
    "            else:\n",
    "                print(f\"Missing mask: {mask_name}\")\n",
    "                corrupt_indices.append(idx)\n",
    "    \n",
    "    return corrupt_indices\n",
    "\n",
    "# Process datasets for classification (images only)\n",
    "for df, name in [(train_df, \"train\"), (val_df, \"val\"), (test_df, \"test\")]:\n",
    "    corrupt = check_corrupt_samples(df, 'archive/images', mask_dir=None, require_masks=False)\n",
    "    if corrupt:\n",
    "        df.drop(corrupt, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"{name.capitalize()} set size after image check: {len(df)}\")\n",
    "\n",
    "# Create a separate copy for segmentation (images + masks)\n",
    "seg_train_df = train_df.copy()\n",
    "seg_val_df = val_df.copy()\n",
    "seg_test_df = test_df.copy()\n",
    "\n",
    "for df, name in [(seg_train_df, \"train\"), (seg_val_df, \"val\"), (seg_test_df, \"test\")]:\n",
    "    corrupt = check_corrupt_samples(df, 'archive/images', 'archive/masks', require_masks=True)\n",
    "    if corrupt:\n",
    "        df.drop(corrupt, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"Segmentation {name.capitalize()} set size after mask check: {len(df)}\")\n",
    "    if len(df) == 0:\n",
    "        print(f\"Warning: Segmentation {name} set is empty. Masks may be missing in 'archive/masks'.\")\n",
    "\n",
    "# Create label mapping\n",
    "all_data = pd.concat([train_df, val_df, test_df])\n",
    "label_mapping = {label: idx for idx, label in enumerate(sorted(all_data['dx'].unique()))}\n",
    "\n",
    "print(\"\\nClass distributions:\")\n",
    "print(\"Training:\", train_df['dx'].value_counts(normalize=True))\n",
    "print(\"Validation:\", val_df['dx'].value_counts(normalize=True))\n",
    "print(\"Test:\", test_df['dx'].value_counts(normalize=True))\n",
    "print(\"\\nLabel mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 3. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Classes\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx]['image_id'] + '.jpg'\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.label_mapping[self.df.iloc[idx]['dx']]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, mask_dir, transform=None, mask_transform=None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx]['image_id'] + '.jpg'\n",
    "        mask_name = self.df.iloc[idx]['image_id'] + '_segmentation.png'  # Updated to match actual naming\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        mask_path = os.path.join(self.mask_dir, mask_name)\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "            \n",
    "        return image, mask\n",
    "\n",
    "# Transforms\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize(224, interpolation=InterpolationMode.NEAREST),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "classification_train = ClassificationDataset(train_df, 'archive/images', img_transform)\n",
    "classification_val = ClassificationDataset(val_df, 'archive/images', img_transform)\n",
    "classification_test = ClassificationDataset(test_df, 'archive/images', img_transform)\n",
    "\n",
    "# Create segmentation datasets\n",
    "segmentation_train = SegmentationDataset(seg_train_df, 'archive/images', 'archive/masks', \n",
    "                                       img_transform, mask_transform)\n",
    "segmentation_val = SegmentationDataset(seg_val_df, 'archive/images', 'archive/masks',\n",
    "                                     img_transform, mask_transform)\n",
    "segmentation_test = SegmentationDataset(seg_test_df, 'archive/images', 'archive/masks',\n",
    "                                      img_transform, mask_transform)\n",
    "\n",
    "# Check for empty datasets\n",
    "for dataset, name in [(classification_train, \"classification_train\"),\n",
    "                      (classification_val, \"classification_val\"),\n",
    "                      (segmentation_train, \"segmentation_train\"),\n",
    "                      (segmentation_val, \"segmentation_val\")]:\n",
    "    if len(dataset) == 0:\n",
    "        raise ValueError(f\"Dataset {name} is empty after preprocessing. Check file paths or data availability.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 4. Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinCancerClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super().__init__()\n",
    "        # Load pre-trained ResNet-18\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Replace final fully connected layer\n",
    "        num_features = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "# Instantiate and verify model\n",
    "classification_model = SkinCancerClassifier().to(device)\n",
    "print(f\"Classification model parameters: {sum(p.numel() for p in classification_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 5. Segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super().__init__()\n",
    "        # Encoder (ResNet-18 backbone)\n",
    "        self.encoder = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Encoder layers\n",
    "        self.conv1 = nn.Sequential(\n",
    "            self.encoder.conv1,\n",
    "            self.encoder.bn1,\n",
    "            self.encoder.relu,\n",
    "            self.encoder.maxpool\n",
    "        )\n",
    "        self.encoder1 = self.encoder.layer1  # Output: 64 channels\n",
    "        self.encoder2 = self.encoder.layer2  # Output: 128 channels\n",
    "        self.encoder3 = self.encoder.layer3  # Output: 256 channels\n",
    "        self.encoder4 = self.encoder.layer4  # Output: 512 channels\n",
    "        \n",
    "        # Decoder layers\n",
    "        self.decoder4 = DecoderBlock(512, 256)  # Upsample 512 -> 256\n",
    "        self.decoder3 = DecoderBlock(256, 128)  # Upsample 256 -> 128\n",
    "        self.decoder2 = DecoderBlock(128, 64)   # Upsample 128 -> 64\n",
    "        self.decoder1 = DecoderBlock(64, 64)    # Upsample 64 -> 64\n",
    "        \n",
    "        # Final output layer\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, out_channels, kernel_size=1)  # Output: 1 channel (binary mask)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.conv1(x)       # Initial conv + maxpool\n",
    "        e1 = self.encoder1(x)   # Layer 1\n",
    "        e2 = self.encoder2(e1)  # Layer 2\n",
    "        e3 = self.encoder3(e2)  # Layer 3\n",
    "        e4 = self.encoder4(e3)  # Layer 4\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        d4 = self.decoder4(e4) + e3  # Upsample + skip connection\n",
    "        d3 = self.decoder3(d4) + e2  # Upsample + skip connection\n",
    "        d2 = self.decoder2(d3) + e1  # Upsample + skip connection\n",
    "        d1 = self.decoder1(d2)       # Final upsample\n",
    "        \n",
    "        # Final output\n",
    "        return self.final(d1)\n",
    "\n",
    "# Instantiate and verify model\n",
    "segmentation_model = UNet().to(device)\n",
    "print(f\"Segmentation model parameters: {sum(p.numel() for p in segmentation_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 6. Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, task='classification'):\n",
    "    \"\"\"\n",
    "    Train a model for classification or segmentation.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        train_loader (DataLoader): DataLoader for training data.\n",
    "        val_loader (DataLoader): DataLoader for validation data.\n",
    "        criterion: Loss function.\n",
    "        optimizer: Optimizer.\n",
    "        num_epochs (int): Number of epochs to train.\n",
    "        task (str): 'classification' or 'segmentation'.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Training and validation history.\n",
    "    \"\"\"\n",
    "    best_loss = float('inf')\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        progress = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        for inputs, targets in progress:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            if task == 'segmentation':\n",
    "                loss = criterion(outputs, targets)\n",
    "            else:\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            progress.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        # Calculate average training loss for the epoch\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, task)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        if task == 'classification':\n",
    "            history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), f'best_{task}_model.pth')\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f\"{task.capitalize()} Epoch {epoch+1}: \"\n",
    "              f\"Train Loss: {train_loss:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}\" + \n",
    "              (f\", Val Acc: {val_acc:.2f}%\" if task == 'classification' else \"\"))\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader, criterion, task='classification'):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a given dataset.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The model to evaluate.\n",
    "        loader (DataLoader): DataLoader for evaluation data.\n",
    "        criterion: Loss function.\n",
    "        task (str): 'classification' or 'segmentation'.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (average loss, accuracy (if classification))\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            if task == 'segmentation':\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "            else:\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    if task == 'classification':\n",
    "        accuracy = 100 * correct / total\n",
    "        return avg_loss, accuracy\n",
    "    return avg_loss, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 7. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Classification Model\n",
    "clf_criterion = nn.CrossEntropyLoss()\n",
    "clf_optimizer = optim.Adam(classification_model.parameters(), lr=1e-4)\n",
    "clf_history = train_model(classification_model, \n",
    "                         DataLoader(classification_train, 32, shuffle=True),\n",
    "                         DataLoader(classification_val, 32),\n",
    "                         clf_criterion, clf_optimizer, \n",
    "                         num_epochs=15, task='classification')\n",
    "\n",
    "# Train Segmentation Model\n",
    "seg_criterion = nn.BCEWithLogitsLoss()\n",
    "seg_optimizer = optim.Adam(segmentation_model.parameters(), lr=1e-4)\n",
    "seg_history = train_model(segmentation_model, \n",
    "                         DataLoader(segmentation_train, 16, shuffle=True),\n",
    "                         DataLoader(segmentation_val, 16),\n",
    "                         seg_criterion, seg_optimizer,\n",
    "                         num_epochs=25, task='segmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 8. Evaluation and Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou_dice(pred_mask, true_mask):\n",
    "    \"\"\"Calculate Intersection over Union (IoU) and Dice coefficient.\"\"\"\n",
    "    pred_mask = (pred_mask > 0.5).float()\n",
    "    true_mask = (true_mask > 0.5).float()\n",
    "    \n",
    "    intersection = (pred_mask * true_mask).sum()\n",
    "    union = pred_mask.sum() + true_mask.sum() - intersection\n",
    "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "    dice = (2 * intersection + 1e-6) / (pred_mask.sum() + true_mask.sum() + 1e-6)\n",
    "    return iou.item(), dice.item()\n",
    "\n",
    "def generate_classification_report(model, loader):\n",
    "    \"\"\"Generate classification report with metrics.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_targets, all_preds, target_names=label_mapping.keys()))\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(confusion_matrix(all_targets, all_preds), \n",
    "                annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=label_mapping.keys(),\n",
    "                yticklabels=label_mapping.keys())\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def generate_segmentation_report(model, loader):\n",
    "    \"\"\"Generate segmentation metrics and visualizations.\"\"\"\n",
    "    model.eval()\n",
    "    ious, dices = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, masks in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = torch.sigmoid(model(inputs))\n",
    "            preds = (outputs > 0.5).float()\n",
    "            \n",
    "            for pred, mask in zip(preds, masks.to(device)):\n",
    "                iou, dice = calculate_iou_dice(pred, mask)\n",
    "                ious.append(iou)\n",
    "                dices.append(dice)\n",
    "    \n",
    "    print(f\"Mean IoU: {np.mean(ious):.4f}\")\n",
    "    print(f\"Mean Dice: {np.mean(dices):.4f}\")\n",
    "    \n",
    "    # Visualization\n",
    "    sample = next(iter(loader))\n",
    "    inputs, masks = sample\n",
    "    outputs = torch.sigmoid(model(inputs.to(device)))\n",
    "    preds = (outputs > 0.5).float().cpu()\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    for i in range(3):\n",
    "        plt.subplot(3, 4, i * 4 + 1)\n",
    "        plt.imshow(inputs[i].permute(1, 2, 0).numpy() * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406])\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(3, 4, i * 4 + 2)\n",
    "        plt.imshow(masks[i].squeeze(), cmap='gray')\n",
    "        plt.title('Ground Truth Mask')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(3, 4, i * 4 + 3)\n",
    "        plt.imshow(preds[i].squeeze(), cmap='gray')\n",
    "        plt.title('Predicted Mask')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(3, 4, i * 4 + 4)\n",
    "        plt.imshow((preds[i].squeeze() > 0.5).astype(float), cmap='jet', alpha=0.5)\n",
    "        plt.imshow(inputs[i].permute(1, 2, 0).numpy() * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406])\n",
    "        plt.title('Overlay')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate final reports\n",
    "print(\"\\nFinal Classification Performance:\")\n",
    "generate_classification_report(classification_model,  DataLoader(classification_test, 32))\n",
    "\n",
    "print(\"\\nFinal Segmentation Performance:\")\n",
    "generate_segmentation_report(segmentation_model,\n",
    "                            DataLoader(segmentation_test, 16))\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(clf_history['train_loss'], label='Train Loss')\n",
    "plt.plot(clf_history['val_loss'], label='Val Loss')\n",
    "plt.plot(clf_history['val_acc'], label='Val Accuracy')\n",
    "plt.title('Classification Training')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(seg_history['train_loss'], label='Train Loss')\n",
    "plt.plot(seg_history['val_loss'], label='Val Loss')\n",
    "plt.title('Segmentation Training')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 9. Single Model for Both Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super().__init__()\n",
    "        # Shared encoder\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        self.encoder = nn.Sequential(\n",
    "            self.base_model.conv1,\n",
    "            self.base_model.bn1,\n",
    "            self.base_model.relu,\n",
    "            self.base_model.maxpool,\n",
    "            self.base_model.layer1,\n",
    "            self.base_model.layer2,\n",
    "            self.base_model.layer3,\n",
    "            self.base_model.layer4\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Segmentation decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            DecoderBlock(512, 256),\n",
    "            DecoderBlock(256, 128),\n",
    "            DecoderBlock(128, 64),\n",
    "            DecoderBlock(64, 64),\n",
    "            nn.Conv2d(64, 1, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        cls_out = self.classifier(features)\n",
    "        seg_out = self.decoder(features)\n",
    "        return cls_out, seg_out\n",
    "\n",
    "# Initialize and verify\n",
    "multi_task_model = MultiTaskModel().to(device)\n",
    "print(f\"Parameters: {sum(p.numel() for p in multi_task_model.parameters()):,}\")\n",
    "\n",
    "# Create multi-task dataset\n",
    "class MultiTaskDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, mask_dir):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.mask_transform = transforms.Compose([\n",
    "            transforms.Resize(224, InterpolationMode.NEAREST),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, f\"{self.df.iloc[idx]['image_id']}.jpg\")\n",
    "        mask_path = os.path.join(self.mask_dir, f\"{self.df.iloc[idx]['image_id']}_mask.jpg\")\n",
    "        label = label_mapping[self.df.iloc[idx]['dx']]\n",
    "        return self.transform(Image.open(img_path)), (\n",
    "            torch.tensor(label, dtype=torch.long),\n",
    "            self.mask_transform(Image.open(mask_path).convert('L'))\n",
    "        )\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "# Training loop\n",
    "multitask_train = MultiTaskDataset(train_df, 'archive/images', 'archive/masks')\n",
    "train_loader = DataLoader(multitask_train, 16, shuffle=True)\n",
    "\n",
    "clf_criterion = nn.CrossEntropyLoss()\n",
    "seg_criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(multi_task_model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(10):\n",
    "    multi_task_model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for images, (labels, masks) in tqdm(train_loader):\n",
    "        images, labels, masks = images.to(device), labels.to(device), masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cls_pred, seg_pred = multi_task_model(images)\n",
    "        loss = clf_criterion(cls_pred, labels) + seg_criterion(seg_pred, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Loss {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "test_loader = DataLoader(\n",
    "    MultiTaskDataset(test_df, 'archive/images', 'archive/masks'), \n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_acc, total_iou, total_dice = 0, 0, 0\n",
    "    for images, (labels, masks) in test_loader:\n",
    "        images, labels, masks = images.to(device), labels.to(device), masks.to(device)\n",
    "        cls_pred, seg_pred = multi_task_model(images)\n",
    "        \n",
    "        total_acc += (cls_pred.argmax(1) == labels).float().mean().item()\n",
    "        iou, dice = calculate_iou_dice(seg_pred, masks)\n",
    "        total_iou += iou\n",
    "        total_dice += dice\n",
    "\n",
    "    print(f\"Accuracy: {total_acc/len(test_loader):.4f}, \"\n",
    "          f\"IoU: {total_iou/len(test_loader):.4f}, \"\n",
    "          f\"Dice: {total_dice/len(test_loader):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
